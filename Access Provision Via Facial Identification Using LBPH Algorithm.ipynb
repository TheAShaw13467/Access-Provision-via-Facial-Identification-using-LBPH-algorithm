{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition using LBPH Face Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to execute the program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Software used: Jupyter Notebook/Google colab, Pyhton 3.9.x\n",
    "\n",
    "\n",
    "Instructions to execute the code:\n",
    "\n",
    "The first code block will import all the necessary libraries that we need in this project(In case that one does not have these libraries installed in his/her system, the IDE will throw a ModuleNotFoundError which can be resolved by simply installing the required libraries)\n",
    "\n",
    "When the second block of code which is \"Creating the Training data\", is executed it pops open a window which will capture 100 images of the face that it finds in front of the camera\n",
    "\n",
    "The third block of code is written to train the model with that data that it just just captured in the above step. It will take not more than 2-3 seconds to train the model(depending on the specifications of the system that one's using).\n",
    "\n",
    "The fourth block of code is actually a function which is created to verify the face according to the trained model.\n",
    "\n",
    "Fifth block of code is an extra hand gesture(show a straight hand and then make a fist) verification that is added to ensure a real person is attempting to acces the system. After the execution of this block the function that we defined in the fourth block will be caleed and the face of the user will be verified according to the threshold of the confidence level that we set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1 - Creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceClassifier = cv2.CascadeClassifier('F:/LBPH Minor Project/haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def faceExtractor(img):\n",
    "    grayScaleImage = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faceCaptures = faceClassifier.detectMultiScale(grayScaleImage, 1.3, 5)\n",
    "\n",
    "    if faceCaptures is ():\n",
    "        return None\n",
    "    for (x,y,w,h) in faceCaptures:\n",
    "        croppedFace = img[y:y+h, x:x+w]\n",
    "    return croppedFace\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collecting 100 samples of the face from webcam input\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if faceExtractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(faceExtractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        file_name_path = 'F:/LBPH Minor Project/faces/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "\n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Getting the training data we previously made\n",
    "data_path = 'F:/LBPH Minor Project/faces/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Creating arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Opening the training images in our datapath\n",
    "# Creating a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Creating a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initializing the facial recognizer\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Training the model \n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Defining a method to verify the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifyFace():\n",
    "    faceClassifier = cv2.CascadeClassifier('F:/LBPH Minor Project/haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "    def face_detector(img, size=0.5):\n",
    "\n",
    "        # Convert image to grayscale\n",
    "        grayScaleImage = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faceCaptures = faceClassifier.detectMultiScale(grayScaleImage, 1.3, 5)\n",
    "        if faceCaptures is ():\n",
    "            return img, []\n",
    "\n",
    "        for (x,y,w,h) in faceCaptures:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "            roi = img[y:y+h, x:x+w]\n",
    "            roi = cv2.resize(roi, (200, 200))\n",
    "        return img, roi\n",
    "\n",
    "\n",
    "    #Open the Webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        image, face = face_detector(frame)\n",
    "        try:\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Pass face to prediction model\n",
    "            # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "            results = model.predict(face)\n",
    "\n",
    "            if results[1] < 500:\n",
    "                confidence = int( 100 * (1 - (results[1])/400) )\n",
    "                display_string = str(confidence) + '% Confident it is User'\n",
    "\n",
    "            cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "\n",
    "            if confidence > 75:\n",
    "                cv2.putText(image, \"Unlocked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow('Face Recognition', image )\n",
    "            else:\n",
    "                cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "                cv2.imshow('Face Recognition', image )\n",
    "\n",
    "        except:\n",
    "            cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            pass\n",
    "\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Gesture verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands() \n",
    "\n",
    "def getCoordinates(id, h, w):\n",
    "    cx, cy = lm.x*w, lm.y*h\n",
    "    cv2.circle(img, (int(cx), int(cy)), 1, (255,255,255), cv2.FILLED)  \n",
    "    return cx, cy\n",
    "\n",
    "startFaceRecognition=0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    if not success: \n",
    "        break\n",
    "    \n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "\n",
    "    h, w, c = img.shape\n",
    "    handsup=0\n",
    "    thumbs_correct=0\n",
    "    fingers_correct=0\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLms in results.multi_hand_landmarks:\n",
    "            for id, lm in enumerate(handLms.landmark):\n",
    "                if id == 0: \n",
    "                    __, cy_0 = getCoordinates(0, h, w)\n",
    "                if id == 10: \n",
    "                    __, cy_10 = getCoordinates(10, h, w)\n",
    "            \n",
    "                if id == 2:\n",
    "                    __, cy_2 = getCoordinates(2, h, w)\n",
    "                if id == 3:\n",
    "                    __, cy_3 = getCoordinates(3, h, w)\n",
    "            \n",
    "                if id == 5: \n",
    "                    __, cy_5 = getCoordinates(5, h, w)\n",
    "                if id == 9: \n",
    "                    __, cy_9 = getCoordinates(9, h, w)\n",
    "                if id == 13: \n",
    "                    __, cy_13 = getCoordinates(13, h, w)\n",
    "                if id == 17: \n",
    "                    __, cy_17 = getCoordinates(17, h, w)\n",
    "                    \n",
    "                if id == 8: \n",
    "                    __, cy_8 = getCoordinates(8, h, w)  \n",
    "                if id == 12: \n",
    "                    __, cy_12 = getCoordinates(12, h, w)\n",
    "                if id == 16: \n",
    "                    __, cy_16 = getCoordinates(16, h, w)\n",
    "                if id == 20: \n",
    "                    __, cy_20 = getCoordinates(20, h, w)\n",
    "            \n",
    "            if cy_10 < cy_0:\n",
    "                handsup=1\n",
    "            else:\n",
    "                handsup=0\n",
    "                    \n",
    "            if (cy_2 > cy_10 and cy_2 < cy_0) and (cy_3 > cy_10 and cy_3 < cy_0):\n",
    "                thumbs_correct=1\n",
    "            else:\n",
    "                thumbs_correct=0\n",
    "            \n",
    "            if (cy_5 < cy_8) and (cy_9 < cy_12) and (cy_13 < cy_16) and (cy_17 < cy_20):\n",
    "                fingers_correct=1\n",
    "            else:\n",
    "                figners_correct=0\n",
    "            \n",
    "            if handsup==1 and thumbs_correct==1 and fingers_correct==1 and startFaceRecognition==0:\n",
    "                startFaceRecognition=1\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "    if startFaceRecognition==1:\n",
    "        break\n",
    "\n",
    "verifyFace()        \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
